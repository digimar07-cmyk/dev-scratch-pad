"""\nCore — Ollama Text Generation\nGeração de texto com modelos Qwen2.5\n"""\n\nimport time\nfrom config import LOGGER\n\n\nclass OllamaTextGenerator:\n    def __init__(self, ollama_client, stop_flag=None):\n        self.client = ollama_client\n        self.stop_flag = stop_flag\n\n    def generate_text(self, prompt, role="text_quality", temperature=0.7, num_predict=350):\n        """\n        Gera texto com o modelo definido por `role`.\n        Usa instruction format adequado para Qwen2.5-Instruct.\n        """\n        if self.stop_flag and getattr(self.stop_flag, "stop_analysis", False):\n            return ""\n        if not self.client.is_available():\n            LOGGER.warning("Ollama indisponível. Usando fallback.")\n            return ""\n\n        model = self.client.get_model_name(role)\n        timeout = self.client.get_timeout(role)\n\n        payload = {\n            "model": model,\n            "messages": [\n                {\n                    "role": "system",\n                    "content": (\n                        "Você é um assistente especialista em produtos de corte laser, "\n                        "decoração artesanal e objetos afetivos personalizados. "\n                        "Responda SEMPRE em português brasileiro. "\n                        "Siga as instruções de formato com precisão."\n                    ),\n                },\n                {"role": "user", "content": prompt},\n            ],\n            "stream": False,\n            "options": {\n                "temperature": temperature,\n                "top_p": 0.9,\n                "top_k": 40,\n                "num_predict": num_predict,\n                "repeat_penalty": 1.1,\n            },\n        }\n\n        last_err = None\n        for attempt in range(1, self.client.retries + 1):\n            if self.stop_flag and getattr(self.stop_flag, "stop_analysis", False):\n                return ""\n            try:\n                resp = self.client.session.post(\n                    f"{self.client.base_url}/api/chat",\n                    json=payload,\n                    timeout=timeout,\n                )\n                if resp.status_code != 200:\n                    raise RuntimeError(f"Ollama HTTP {resp.status_code}: {resp.text[:200]}")\n                data = resp.json()\n                text = (data.get("message") or {}).get("content") or data.get("response") or ""\n                LOGGER.info(f"✅ [{model}] gerou resposta ({len(text)} chars)")\n                return text.strip()\n            except Exception as e:\n                last_err = e\n                LOGGER.warning(f"Ollama falhou (tentativa {attempt}/{self.client.retries}) [{model}]: {e}")\n                if attempt < self.client.retries:\n                    time.sleep(2.0)\n        if last_err:\n            LOGGER.error(f"Ollama falhou definitivamente [{model}]: {last_err}", exc_info=True)\n        return ""\n